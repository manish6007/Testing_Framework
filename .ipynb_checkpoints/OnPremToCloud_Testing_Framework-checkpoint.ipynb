{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef3fe8e5",
   "metadata": {},
   "source": [
    "# Oracle vs Athena data comparison using csv extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1692c4e",
   "metadata": {},
   "source": [
    "The code provided performs a comparison between two CSV files, `file1` and `file2`, located in the specified `file_path`. It uses the pandas library to read and manipulate the data, the BeautifulSoup library for HTML parsing, and the webbrowser and os libraries for file handling and opening HTML reports.\n",
    "\n",
    "Functions:\n",
    "1. `open_html_file(file_name)`: Opens an HTML file in the default web browser. Takes the `file_name` as input.\n",
    "2. `compare_files(file_path, file1, file2)`: Compares the data between the two CSV files. Takes `file_path`, `file1`, and `file2` as inputs.\n",
    "\n",
    "    Inside the `compare_files` function:\n",
    "    - The function first reads the CSV files into pandas DataFrames (`df_athena` and `df_oracle`).\n",
    "    - It checks if there is a record count difference between the two tables. If there is a difference, it saves the rows that are present in `df_oracle` but not in `df_athena` to an HTML report named \"comparison_report.html\". The `count_check` variable is set to False to indicate a record count difference.\n",
    "    - If the record count is the same, it compares the data in `df_athena` and `df_oracle` using the `compare` method from pandas. If there are no differences found, it writes a success message to the HTML report and opens it in the default web browser.\n",
    "    - If differences are found, it saves the differences to the \"comparison_report.html\" file and modifies the HTML by adding a title tag if it doesn't exist or updating the existing one.\n",
    "    - The modified HTML report is then written back to the file.\n",
    "\n",
    "Note: The code includes exception handling to catch any errors that might occur during file operations or data processing. If an exception occurs, an appropriate error message is printed, and the function returns False.\n",
    "\n",
    "Please make sure you have the required libraries installed and the files are available in the specified path before using this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fd1343f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the files location: C:/Users/manis/Downloads/Comparison\n",
      "Please enter first file name: oracle.csv\n",
      "Please enter second file name: athena.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import webbrowser\n",
    "import os\n",
    "\n",
    "def open_html_file(file_name):\n",
    "    webbrowser.open(file_name)\n",
    "\n",
    "def compare_files(file_path, file1, file2):\n",
    "    # Read the CSV files into Pandas DataFrames\n",
    "    try:\n",
    "        df_athena = pd.read_csv(f\"{file_path}/{file1}\")\n",
    "        df_oracle = pd.read_csv(f\"{file_path}/{file2}\")\n",
    "    \n",
    "    \n",
    "        # Flag to check if there is a record count difference\n",
    "        count_check = True\n",
    "\n",
    "        # Check if there is a record count difference between the two tables\n",
    "        if len(df_athena) != len(df_oracle):\n",
    "            print(\"There is a record count difference between the two tables.\")\n",
    "\n",
    "            # Get the rows that are present in df_oracle but not in df_athena\n",
    "            df_difference = pd.concat([df_oracle, df_athena]).drop_duplicates(keep=False)\n",
    "\n",
    "            # Save the difference to an HTML report\n",
    "            df_difference.to_html(f\"{file_path}/comparison_report.html\")\n",
    "            count_check = False\n",
    "\n",
    "        # If the record count is the same, compare the data in the DataFrames\n",
    "        if count_check:\n",
    "\n",
    "            # Compare the data in df_athena and df_oracle\n",
    "            df_diff = df_athena.compare(df_oracle, align_axis=0)\n",
    "\n",
    "            # If there are no differences found, write a success message to the HTML report\n",
    "            if df_diff.size == 0:\n",
    "                with open(f\"{file_path}/comparison_report.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "                    # Write the HTML content\n",
    "                    f.write(\"<html><body><h1>Congratulations...No Difference Found between provided files. &#128522;</h1></body></html>\")\n",
    "                    open_html_file(f\"{file_path}/comparison_report.html\")\n",
    "            else:\n",
    "                # Save the differences to an HTML report\n",
    "                df_diff.to_html(f\"{file_path}/comparison_report.html\")\n",
    "\n",
    "                # Modify the HTML report by adding a title tag if it exists or creating a new one\n",
    "                if os.path.exists(f\"{file_path}/comparison_report.html\"):\n",
    "                    with open(f\"{file_path}/comparison_report.html\", \"r\") as f:\n",
    "                        # Parse the HTML file using BeautifulSoup\n",
    "                        soup = BeautifulSoup(f, \"html.parser\")\n",
    "\n",
    "                    # Find the head tag in the parsed HTML\n",
    "                    head_tag = soup.find(\"head\")\n",
    "\n",
    "                    # If head tag exists, add a title tag with the text \"Comparison Report\"\n",
    "                    if head_tag:\n",
    "                        title_tag = soup.new_tag(\"title\")\n",
    "                        title_tag.string = \"Comparison Report\"\n",
    "                        head_tag.append(title_tag)\n",
    "                    else:\n",
    "                        # If head tag doesn't exist, create a new head tag and add the title tag\n",
    "                        head_tag = soup.new_tag(\"head\")\n",
    "                        soup.insert(0, head_tag)\n",
    "                        title_tag = soup.new_tag(\"title\")\n",
    "                        title_tag.string = \"Comparison Report\"\n",
    "                        head_tag.append(title_tag)\n",
    "\n",
    "                    # Write the modified HTML back to the file\n",
    "                    with open(f\"{file_path}/comparison_report.html\", \"w\") as f:\n",
    "                        f.write(str(soup))\n",
    "                else:\n",
    "                    print(\"The HTML report file does not exist.\")\n",
    "        return True\n",
    "    except:\n",
    "        print(f\"File is not available at {file_path}\")\n",
    "        return False\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    file_path = input(\"Please enter the files location: \") #\"C:/Users/manis/Downloads/Comparison\"\n",
    "    athena = input(\"Please enter first file name: \") \n",
    "    oracle = input(\"Please enter second file name: \") \n",
    "    status = compare_files(file_path,athena,oracle)\n",
    "    if status:\n",
    "        file_name = f\"{file_path}/comparison_report.html\"\n",
    "        open_html_file(file_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70c48fa",
   "metadata": {},
   "source": [
    "oracle athena comparison<br>\n",
    "oracle and redshift<br>\n",
    "athena and redshift<br>\n",
    "s3 and oracle<br>\n",
    "oracle and RDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0716dd78",
   "metadata": {},
   "source": [
    "table name check<br>\n",
    "field name check<br>\n",
    "datatype check<br>\n",
    "data check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efc507b",
   "metadata": {},
   "source": [
    "# Athena Vs Oracle (Field Name and Datatype check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c34b9cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cx_Oracle\n",
    "import boto3\n",
    "cx_Oracle.init_oracle_client(lib_dir=r\"C:\\Users\\manis\\Downloads\\instantclient-basic-windows.x64-21.10.0.0.0dbru\\instantclient_21_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c00f880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oracle_columns(user, password, host, port, service_name, table_name):\n",
    "    \"\"\"\n",
    "    Connects to Oracle database and retrieves the columns of a specific table.\n",
    "\n",
    "    Args:\n",
    "        user (str): Oracle database username.\n",
    "        password (str): Oracle database password.\n",
    "        host (str): Oracle database host.\n",
    "        port (int): Oracle database port.\n",
    "        service_name (str): Oracle database service name.\n",
    "        table_name (str): Name of the table to retrieve columns from.\n",
    "\n",
    "    Returns:\n",
    "        list: List of Oracle column descriptions.\n",
    "\n",
    "    \"\"\"\n",
    "    oracle_connection = cx_Oracle.connect(f\"{user}/{password}@{host}:{port}/{service_name}\")\n",
    "    oracle_cursor = oracle_connection.cursor()\n",
    "    oracle_cursor.execute(f\"SELECT * FROM {table_name} WHERE 1=0\")\n",
    "    oracle_columns = oracle_cursor.description\n",
    "    oracle_cursor.close()\n",
    "    oracle_connection.close()\n",
    "    return oracle_columns\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9aead1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('COUNTRY_ID', <cx_Oracle.DbType DB_TYPE_CHAR>, 2, 2, None, None, 0),\n",
       " ('COUNTRY_NAME', <cx_Oracle.DbType DB_TYPE_VARCHAR>, 40, 40, None, None, 1),\n",
       " ('REGION_ID', <cx_Oracle.DbType DB_TYPE_NUMBER>, 127, None, 0, -127, 1)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ora_cols = get_oracle_columns(\"hr\",\"oracle\",\"192.168.56.102\",1521,\"freepdb1\",\"countries\")\n",
    "ora_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13a2334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_athena_columns(region, database, athena_table):\n",
    "    \"\"\"\n",
    "    Connects to Athena and retrieves the columns of a specific table.\n",
    "\n",
    "    Args:\n",
    "        region (str): AWS region name.\n",
    "        database (str): Athena database name.\n",
    "        athena_table (str): Name of the Athena table to retrieve columns from.\n",
    "\n",
    "    Returns:\n",
    "        list: List of Athena column descriptions.\n",
    "\n",
    "    \"\"\"\n",
    "    # Connect to Athena\n",
    "    athena_client = boto3.client('athena', region_name=region)\n",
    "    \n",
    "    # Get the Athena table schema\n",
    "    response = athena_client.get_table_metadata(\n",
    "        CatalogName='AwsDataCatalog',\n",
    "        DatabaseName=database,\n",
    "        TableName=athena_table\n",
    "    )\n",
    "    \n",
    "    athena_columns = response['TableMetadata']['Columns']\n",
    "    return athena_columns\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8453b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_oracle_with_athena_datatype(cx_oracle_datatype):\n",
    "    \"\"\"\n",
    "    Returns the corresponding Athena datatype for the given cx_Oracle datatype.\n",
    "    Args:\n",
    "        cx_oracle_datatype: The cx_Oracle datatype.\n",
    "    Returns:\n",
    "        The corresponding Athena datatype.\n",
    "    \"\"\"\n",
    "    if cx_oracle_datatype[1].name in [\"DB_TYPE_VARCHAR\",\"DB_TYPE_CHAR\", \"DB_TYPE_NCHAR\", \"DB_TYPE_VARCHAR2\", \"DB_TYPE_NVARCHAR2\", \"DB_TYPE_LONG\"]:\n",
    "        return \"STRING\"\n",
    "    elif cx_oracle_datatype[1].name in [\"DB_TYPE_NUMBER\"] and cx_oracle_datatype[5]==0:\n",
    "        return \"INTEGER\"\n",
    "    elif cx_oracle_datatype[1].name in [\"DB_TYPE_NUMBER\", \"DB_TYPE_FLOAT\", \"DB_TYPE_DOUBLE\", \"DB_TYPE_BINARY_FLOAT\", \"DB_TYPE_BINARY_DOUBLE\"]:\n",
    "        return \"DOUBLE\"\n",
    "    elif cx_oracle_datatype[1].name == \"DB_TYPE_DATE\":\n",
    "        return \"DATE\"\n",
    "    elif cx_oracle_datatype[1].name == \"DB_TYPE_TIMESTAMP\":\n",
    "        return \"TIMESTAMP\"\n",
    "    elif cx_oracle_datatype[1].name in [\"DB_TYPE_BLOB\", \"DB_TYPE_CLOB\", \"DB_TYPE_NCLOB\"]:\n",
    "        return \"STRING\"  # Consider using \"BINARY\" for BLOB if necessary\n",
    "    elif cx_oracle_datatype[1].name in [\"DB_TYPE_RAW\", \"DB_TYPE_LONG_RAW\"]:\n",
    "        return \"BINARY\"\n",
    "    elif cx_oracle_datatype[1].name in [\"DB_TYPE_ROWID\", \"DB_TYPE_UROWID\"]:\n",
    "        return \"STRING\"\n",
    "    elif cx_oracle_datatype[1].name == \"DB_TYPE_BOOLEAN\":\n",
    "        return \"BOOLEAN\"\n",
    "    elif cx_oracle_datatype[1].name == \"DB_TYPE_INTERVAL\":\n",
    "        return \"STRING\"\n",
    "    elif cx_oracle_datatype[1].name in [\"DB_TYPE_XML\", \"DB_TYPE_GEOMETRY\", \"DB_TYPE_TOPO_GEOMETRY\", \"DB_TYPE_GEORASTER\"]:\n",
    "        return \"STRING\"\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported cx_Oracle datatype: {}\".format(cx_oracle_datatype.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9f2a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oracle_equivalent_athena_datatypes(username, password, host, port, service_name, table_name):\n",
    "      \"\"\"\n",
    "      Returns the Athena datatypes for the given Oracle table.\n",
    "\n",
    "      Args:\n",
    "        username: The Oracle username.\n",
    "        password: The Oracle password.\n",
    "        host: The Oracle hostname.\n",
    "        port: The Oracle port number.\n",
    "        service_name: The Oracle service name.\n",
    "        table_name: The Oracle table name.\n",
    "\n",
    "      Returns:\n",
    "        A dictionary mapping Oracle column names to Athena datatypes.\n",
    "      \"\"\"\n",
    "        cx_oracle_datatypes = get_oracle_columns(username, password, host, port, service_name, table_name)\n",
    "        athena_datatypes = {}\n",
    "        for cx_oracle_datatype in cx_oracle_datatypes:\n",
    "            athena_datatype = get_athena_datatype(cx_oracle_datatype)\n",
    "            athena_datatypes[cx_oracle_datatype[0]] = athena_datatype\n",
    "\n",
    "        return athena_datatypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "101cfdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_table_data_types(athena_columns, oracle_columns):\n",
    "    \"\"\"\n",
    "    Compares the data types of columns between Athena and Oracle tables.\n",
    "\n",
    "    Args:\n",
    "        athena_columns (list): List of Athena column descriptions.\n",
    "        oracle_columns (list): List of Oracle column descriptions.\n",
    "\n",
    "    Returns:\n",
    "        list: List of differences in column data types.\n",
    "\n",
    "    \"\"\"\n",
    "    differences = []\n",
    "    for athena_col, oracle_col in zip(athena_columns, oracle_columns):\n",
    "        athena_col_name = athena_col['Name']\n",
    "        athena_data_type = athena_col['Type']\n",
    "        \n",
    "        oracle_col_name = oracle_col[0]\n",
    "        oracle_data_type = oracle_col[1].name\n",
    "        \n",
    "        if athena_data_type != oracle_data_type:\n",
    "            difference = {\n",
    "                'column': athena_col_name,\n",
    "                'athena_data_type': athena_data_type,\n",
    "                'oracle_data_type': oracle_data_type\n",
    "            }\n",
    "            differences.append(difference)\n",
    "    return differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7944af80",
   "metadata": {},
   "outputs": [],
   "source": [
    "athena_columns = get_athena_columns(\"ap-south-1\", \"athena_db\", \"countries\"):\n",
    "oracle_columns = get_oracle_columns(\"hr\",\"oracle\",\"192.168.56.102\",1521,\"freepdb1\",\"countries\")\n",
    "differences = compare_table_data_types(athena_columns, oracle_columns)\n",
    "\n",
    "if differences:\n",
    "    print('Differences found:')\n",
    "    for diff in differences:\n",
    "        print(diff)\n",
    "else:\n",
    "    print('No differences found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c7e404",
   "metadata": {},
   "source": [
    "# Data comparison between athena and oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ed59709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cx_Oracle\n",
    "import pandas as pd\n",
    "\n",
    "def read_oracle_table(username, password, host, port, service_name, table_name):\n",
    "    \"\"\"\n",
    "    Reads data from an Oracle table and returns a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        username (str): The username to connect to the Oracle database.\n",
    "        password (str): The password to connect to the Oracle database.\n",
    "        host (str): The hostname or IP address of the Oracle database server.\n",
    "        port (int): The port number to connect to the Oracle database.\n",
    "        service_name (str): The service name of the Oracle database.\n",
    "        table_name (str): The name of the table to fetch data from.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the data from the Oracle table.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Establish a connection to the Oracle database\n",
    "    connection = cx_Oracle.connect(f'{username}/{password}@{host}:{port}/{service_name}')\n",
    "\n",
    "    # Create a cursor object\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Execute a query to fetch data from the Oracle table\n",
    "    query = f'SELECT * FROM {table_name}'\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # Fetch all the rows from the cursor\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    # Get the column names from the cursor description\n",
    "    column_names = [desc[0] for desc in cursor.description]\n",
    "\n",
    "    # Create a pandas DataFrame from the fetched data and column names\n",
    "    df = pd.DataFrame(rows, columns=column_names)\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "\n",
    "    return df\n",
    "\n",
    "# Usage example\n",
    "#df = read_oracle_table('hr', 'oracle', '192.168.56.102', 1521, 'freepdb1', 'countries')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bdc88db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_from_athena_table(region, database, table, output_location):\n",
    "    \"\"\"\n",
    "    Creates a pandas DataFrame by fetching data from an Athena table.\n",
    "\n",
    "    Args:\n",
    "        region (str): The AWS region name.\n",
    "        database (str): The name of the Athena database.\n",
    "        table (str): The name of the Athena table to fetch data from.\n",
    "        output_location (str): The S3 bucket location to store the query results.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the data from the Athena table.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create an Athena client\n",
    "    athena_client = boto3.client('athena', region_name=region)\n",
    "    \n",
    "    # Execute the query to fetch data from the Athena table\n",
    "    query = f'SELECT * FROM {table}'\n",
    "    response = athena_client.start_query_execution(\n",
    "        QueryString=query,\n",
    "        QueryExecutionContext={\n",
    "            'Database': database\n",
    "        },\n",
    "        ResultConfiguration={\n",
    "            'OutputLocation': output_location\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Get the query execution ID\n",
    "    query_execution_id = response['QueryExecutionId']\n",
    "    \n",
    "    # Wait for the query execution to complete\n",
    "    waiter = athena_client.get_waiter('query_execution_complete')\n",
    "    waiter.wait(QueryExecutionId=query_execution_id)\n",
    "    \n",
    "    # Get the query results\n",
    "    results = athena_client.get_query_results(QueryExecutionId=query_execution_id)\n",
    "    \n",
    "    # Extract the column names\n",
    "    column_names = [field['Name'] for field in results['ResultSet']['ResultSetMetadata']['ColumnInfo']]\n",
    "    \n",
    "    # Extract the rows\n",
    "    rows = []\n",
    "    for row in results['ResultSet']['Rows'][1:]:\n",
    "        rows.append([data['VarCharValue'] if 'VarCharValue' in data else None for data in row['Data']])\n",
    "    \n",
    "    # Create the pandas DataFrame\n",
    "    df = pd.DataFrame(rows, columns=column_names)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Usage example\n",
    "#region = 'YOUR_REGION'\n",
    "#database = 'YOUR_DATABASE'\n",
    "#table = 'YOUR_TABLE_NAME'\n",
    "#df = create_dataframe_from_athena_table(region, database, table)\n",
    "#print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90175d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_dataframes(file_path, df1, df2):\n",
    "     \"\"\"\n",
    "    Compares two pandas DataFrames and generates a comparison report.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The directory path to store the comparison report.\n",
    "        df1 (pandas.DataFrame): The first DataFrame to compare.\n",
    "        df2 (pandas.DataFrame): The second DataFrame to compare.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the comparison is successful, False otherwise.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        df_athena = df1\n",
    "        df_oracle = df2\n",
    "    \n",
    "    \n",
    "        # Flag to check if there is a record count difference\n",
    "        count_check = True\n",
    "\n",
    "        # Check if there is a record count difference between the two tables\n",
    "        if len(df_athena) != len(df_oracle):\n",
    "            print(\"There is a record count difference between the two tables.\")\n",
    "\n",
    "            # Get the rows that are present in df_oracle but not in df_athena\n",
    "            df_difference = pd.concat([df_oracle, df_athena]).drop_duplicates(keep=False)\n",
    "\n",
    "            # Save the difference to an HTML report\n",
    "            df_difference.to_html(f\"{file_path}/comparison_report.html\")\n",
    "            count_check = False\n",
    "\n",
    "        # If the record count is the same, compare the data in the DataFrames\n",
    "        if count_check:\n",
    "\n",
    "            # Compare the data in df_athena and df_oracle\n",
    "            df_diff = df_athena.compare(df_oracle, align_axis=0)\n",
    "\n",
    "            # If there are no differences found, write a success message to the HTML report\n",
    "            if df_diff.size == 0:\n",
    "                with open(f\"{file_path}/comparison_report.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "                    # Write the HTML content\n",
    "                    f.write(\"<html><body><h1>Congratulations...No Difference Found between provided datasets. &#128522;</h1></body></html>\")\n",
    "                    open_html_file(f\"{file_path}/comparison_report.html\")\n",
    "            else:\n",
    "                # Save the differences to an HTML report\n",
    "                df_diff.to_html(f\"{file_path}/comparison_report.html\")\n",
    "\n",
    "                # Modify the HTML report by adding a title tag if it exists or creating a new one\n",
    "                if os.path.exists(f\"{file_path}/comparison_report.html\"):\n",
    "                    with open(f\"{file_path}/comparison_report.html\", \"r\") as f:\n",
    "                        # Parse the HTML file using BeautifulSoup\n",
    "                        soup = BeautifulSoup(f, \"html.parser\")\n",
    "\n",
    "                    # Find the head tag in the parsed HTML\n",
    "                    head_tag = soup.find(\"head\")\n",
    "\n",
    "                    # If head tag exists, add a title tag with the text \"Comparison Report\"\n",
    "                    if head_tag:\n",
    "                        title_tag = soup.new_tag(\"title\")\n",
    "                        title_tag.string = \"Comparison Report\"\n",
    "                        head_tag.append(title_tag)\n",
    "                    else:\n",
    "                        # If head tag doesn't exist, create a new head tag and add the title tag\n",
    "                        head_tag = soup.new_tag(\"head\")\n",
    "                        soup.insert(0, head_tag)\n",
    "                        title_tag = soup.new_tag(\"title\")\n",
    "                        title_tag.string = \"Comparison Report\"\n",
    "                        head_tag.append(title_tag)\n",
    "\n",
    "                    # Write the modified HTML back to the file\n",
    "                    with open(f\"{file_path}/comparison_report.html\", \"w\") as f:\n",
    "                        f.write(str(soup))\n",
    "                else:\n",
    "                    print(\"The HTML report file does not exist.\")\n",
    "        return True\n",
    "    except:\n",
    "        print(f\"Something went wrong.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec42a87",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a0c5f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_spark_to_pandas(spark_df):\n",
    "    \"\"\"\n",
    "    Converts a Spark DataFrame to a Pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        spark_df (pyspark.sql.DataFrame): The Spark DataFrame to be converted.\n",
    "        \n",
    "    Returns:\n",
    "        pandas_df (pandas.DataFrame): The resulting Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    pandas_df = spark_df.toPandas()\n",
    "    return pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8454df7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "def create_pandas_dataframe_from_rds_table(host, port, database, username, password, table_name):\n",
    "    \"\"\"\n",
    "    Create a Pandas DataFrame from a table in a remote RDS database.\n",
    "\n",
    "    Parameters:\n",
    "        host (str): The hostname or IP address of the RDS database.\n",
    "        port (int): The port number for the RDS database.\n",
    "        database (str): The name of the database in the RDS instance.\n",
    "        username (str): The username for the RDS database.\n",
    "        password (str): The password for the RDS database.\n",
    "        table_name (str): The name of the table in the RDS database.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the data from the specified table.\n",
    "\n",
    "    Raises:\n",
    "        psycopg2.OperationalError: If there is an error connecting to the RDS database.\n",
    "\n",
    "    Example:\n",
    "        df = create_pandas_dataframe_from_rds_table(\n",
    "            host='example.com',\n",
    "            port=5432,\n",
    "            database='mydb',\n",
    "            username='user',\n",
    "            password='password',\n",
    "            table_name='mytable'\n",
    "        )\n",
    "    \"\"\"\n",
    "    # Establish a connection to the RDS database\n",
    "    conn = psycopg2.connect(\n",
    "        host=host,\n",
    "        port=port,\n",
    "        database=database,\n",
    "        user=username,\n",
    "        password=password\n",
    "    )\n",
    "\n",
    "    # Create a cursor object to interact with the database\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Execute a SQL query to fetch all data from the table\n",
    "    query = f\"SELECT * FROM {table_name}\"\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # Fetch all rows from the result set\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    # Get the column names from the cursor description\n",
    "    column_names = [desc[0] for desc in cursor.description]\n",
    "\n",
    "    # Create a Pandas DataFrame from the fetched data and column names\n",
    "    df = pd.DataFrame(rows, columns=column_names)\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "037ea406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "def create_pandas_dataframe_from_redshift_table(host, port, database, username, password, table_name):\n",
    "    \"\"\"\n",
    "    Create a Pandas DataFrame from a Redshift table.\n",
    "\n",
    "    Parameters:\n",
    "        host (str): The hostname or IP address of the Redshift cluster.\n",
    "        port (int): The port number used to connect to the Redshift cluster.\n",
    "        database (str): The name of the Redshift database.\n",
    "        username (str): The username used to authenticate the connection.\n",
    "        password (str): The password used to authenticate the connection.\n",
    "        table_name (str): The name of the table from which to fetch the data.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the fetched data from the table.\n",
    "\n",
    "    Raises:\n",
    "        psycopg2.OperationalError: If there is an error in establishing the connection to the Redshift cluster.\n",
    "\n",
    "    Example:\n",
    "        host = 'example-redshift-cluster.com'\n",
    "        port = 5439\n",
    "        database = 'my_database'\n",
    "        username = 'my_username'\n",
    "        password = 'my_password'\n",
    "        table_name = 'my_table'\n",
    "        df = create_pandas_dataframe_from_redshift_table(host, port, database, username, password, table_name)\n",
    "    \"\"\"\n",
    "    # Establish a connection to the Redshift cluster\n",
    "    conn = psycopg2.connect(\n",
    "        host=host,\n",
    "        port=port,\n",
    "        database=database,\n",
    "        user=username,\n",
    "        password=password\n",
    "    )\n",
    "\n",
    "    # Create a cursor object to interact with the database\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Execute a SQL query to fetch all data from the table\n",
    "    query = f\"SELECT * FROM {table_name}\"\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # Fetch all rows from the result set\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    # Get the column names from the cursor description\n",
    "    column_names = [desc[0] for desc in cursor.description]\n",
    "\n",
    "    # Create a Pandas DataFrame from the fetched data and column names\n",
    "    df = pd.DataFrame(rows, columns=column_names)\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e6e2780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "def create_pandas_dataframe_from_rds_table(host, port, database, username, password, table_name):\n",
    "    \"\"\"\n",
    "    Creates a Pandas DataFrame from an RDS table.\n",
    "\n",
    "    Args:\n",
    "        host (str): The hostname or IP address of the RDS instance.\n",
    "        port (int): The port number to connect to the RDS instance.\n",
    "        database (str): The name of the RDS database.\n",
    "        username (str): The username for authentication.\n",
    "        password (str): The password for authentication.\n",
    "        table_name (str): The name of the table in the RDS database.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the data from the RDS table.\n",
    "    \"\"\"\n",
    "\n",
    "    # Establish a connection to the RDS database\n",
    "    conn = psycopg2.connect(\n",
    "        host=host,\n",
    "        port=port,\n",
    "        database=database,\n",
    "        user=username,\n",
    "        password=password\n",
    "    )\n",
    "\n",
    "    # Create a cursor object to interact with the database\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Execute a SQL query to fetch all data from the table\n",
    "    query = f\"SELECT * FROM {table_name}\"\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # Fetch all rows from the result set\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    # Get the column names from the cursor description\n",
    "    column_names = [desc[0] for desc in cursor.description]\n",
    "\n",
    "    # Create a Pandas DataFrame from the fetched data and column names\n",
    "    df = pd.DataFrame(rows, columns=column_names)\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30d33d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "def create_pandas_dataframe_from_s3_parquet_and_pyspark_table(parquet_file_path, spark_table_name):\n",
    "    \"\"\"\n",
    "    Creates a Pandas DataFrame from an S3 Parquet file and a PySpark table.\n",
    "\n",
    "    Args:\n",
    "        parquet_file_path (str): The S3 path of the Parquet file.\n",
    "        spark_table_name (str): The name of the PySpark table.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The resulting Pandas DataFrame.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a SparkSession\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "    # Read the Parquet file into a PySpark DataFrame\n",
    "    spark_df = spark.read.parquet(parquet_file_path)\n",
    "\n",
    "    # Register the PySpark DataFrame as a temporary table\n",
    "    spark_df.createOrReplaceTempView(spark_table_name)\n",
    "\n",
    "    # Convert the PySpark table to a Pandas DataFrame\n",
    "    pandas_df = spark.sql(f\"SELECT * FROM {spark_table_name}\").toPandas()\n",
    "\n",
    "    return pandas_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a1d3661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import cx_Oracle\n",
    "\n",
    "def compare_datatypes_redshift_oracle(redshift_conn_params, oracle_conn_params, table_name):\n",
    "    \"\"\"\n",
    "    Compares the data types between Redshift and Oracle databases for a given table.\n",
    "\n",
    "    Args:\n",
    "        redshift_conn_params (dict): A dictionary containing the connection parameters for Redshift.\n",
    "            Example: {'host': 'your-redshift-hostname', 'port': 5439, 'database': 'your-database-name',\n",
    "                      'username': 'your-username', 'password': 'your-password'}\n",
    "\n",
    "        oracle_conn_params (dict): A dictionary containing the connection parameters for Oracle.\n",
    "            Example: {'host': 'your-oracle-hostname', 'port': 1521, 'database': 'your-database-name',\n",
    "                      'username': 'your-username', 'password': 'your-password'}\n",
    "\n",
    "        table_name (str): The name of the table to compare.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the mapping of column names and their corresponding data types.\n",
    "            Example: {'column1': ('redshift_type', 'oracle_type'), 'column2': ('redshift_type', 'oracle_type'), ...}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Establish a connection to Redshift\n",
    "    redshift_conn = psycopg2.connect(\n",
    "        host=redshift_conn_params['host'],\n",
    "        port=redshift_conn_params['port'],\n",
    "        database=redshift_conn_params['database'],\n",
    "        user=redshift_conn_params['username'],\n",
    "        password=redshift_conn_params['password']\n",
    "    )\n",
    "\n",
    "    # Create a cursor for Redshift\n",
    "    redshift_cursor = redshift_conn.cursor()\n",
    "\n",
    "    # Get the column names and data types from Redshift\n",
    "    redshift_cursor.execute(f\"SELECT column_name, data_type FROM information_schema.columns WHERE table_name='{table_name}'\")\n",
    "    redshift_columns = redshift_cursor.fetchall()\n",
    "\n",
    "    # Establish a connection to Oracle\n",
    "    oracle_conn = cx_Oracle.connect(\n",
    "        f\"{oracle_conn_params['username']}/{oracle_conn_params['password']}@{oracle_conn_params['host']}:\"\n",
    "        f\"{oracle_conn_params['port']}/{oracle_conn_params['database']}\"\n",
    "    )\n",
    "\n",
    "    # Create a cursor for Oracle\n",
    "    oracle_cursor = oracle_conn.cursor()\n",
    "\n",
    "    # Get the column names and data types from Oracle\n",
    "    oracle_cursor.execute(f\"SELECT column_name, data_type FROM all_tab_columns WHERE table_name='{table_name.upper()}'\")\n",
    "    oracle_columns = oracle_cursor.fetchall()\n",
    "\n",
    "    # Close the cursors and connections\n",
    "    redshift_cursor.close()\n",
    "    redshift_conn.close()\n",
    "    oracle_cursor.close()\n",
    "    oracle_conn.close()\n",
    "\n",
    "    # Create a dictionary to store the mapping of column names and data types\n",
    "    column_datatypes = {}\n",
    "\n",
    "    # Compare the data types between Redshift and Oracle\n",
    "    for redshift_col, oracle_col in zip(redshift_columns, oracle_columns):\n",
    "        column_name = redshift_col[0]\n",
    "        redshift_datatype = redshift_col[1]\n",
    "        oracle_datatype = oracle_col[1]\n",
    "\n",
    "        column_datatypes[column_name] = (redshift_datatype, oracle_datatype)\n",
    "\n",
    "    return column_datatypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5618d7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\manis\\\\Testing_Framework'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357e3a25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
