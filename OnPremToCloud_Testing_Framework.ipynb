{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef3fe8e5",
   "metadata": {},
   "source": [
    "# Oracle vs Athena data comparison using csv extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1692c4e",
   "metadata": {},
   "source": [
    "The code provided performs a comparison between two CSV files, `file1` and `file2`, located in the specified `file_path`. It uses the pandas library to read and manipulate the data, the BeautifulSoup library for HTML parsing, and the webbrowser and os libraries for file handling and opening HTML reports.\n",
    "\n",
    "Functions:\n",
    "1. `open_html_file(file_name)`: Opens an HTML file in the default web browser. Takes the `file_name` as input.\n",
    "2. `compare_files(file_path, file1, file2)`: Compares the data between the two CSV files. Takes `file_path`, `file1`, and `file2` as inputs.\n",
    "\n",
    "    Inside the `compare_files` function:\n",
    "    - The function first reads the CSV files into pandas DataFrames (`df_athena` and `df_oracle`).\n",
    "    - It checks if there is a record count difference between the two tables. If there is a difference, it saves the rows that are present in `df_oracle` but not in `df_athena` to an HTML report named \"comparison_report.html\". The `count_check` variable is set to False to indicate a record count difference.\n",
    "    - If the record count is the same, it compares the data in `df_athena` and `df_oracle` using the `compare` method from pandas. If there are no differences found, it writes a success message to the HTML report and opens it in the default web browser.\n",
    "    - If differences are found, it saves the differences to the \"comparison_report.html\" file and modifies the HTML by adding a title tag if it doesn't exist or updating the existing one.\n",
    "    - The modified HTML report is then written back to the file.\n",
    "\n",
    "Note: The code includes exception handling to catch any errors that might occur during file operations or data processing. If an exception occurs, an appropriate error message is printed, and the function returns False.\n",
    "\n",
    "Please make sure you have the required libraries installed and the files are available in the specified path before using this code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2a592f",
   "metadata": {},
   "source": [
    "# Functions to generate different report types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53b6f5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import webbrowser\n",
    "import os\n",
    "import cx_Oracle\n",
    "import boto3\n",
    "\n",
    "cx_Oracle.init_oracle_client(lib_dir=r\"C:\\Users\\manis\\Downloads\\instantclient-basic-windows.x64-21.10.0.0.0dbru\\instantclient_21_10\")\n",
    "\n",
    "# Function to generate HTML report\n",
    "def generate_html_report(comparison_results_df,file_path):\n",
    "    if comparison_results_df.size == 0:\n",
    "        with open(f\"{file_path}/comparison_report.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "            # Write the HTML content\n",
    "            f.write(\"<html><body><h1>Congratulations...No Difference Found between provided datasets. &#128522;</h1></body></html>\")\n",
    "            print(\"There is no fifference in provided datasets.\")\n",
    "            open_html_file(f\"{file_path}/comparison_report.html\")\n",
    "    else:\n",
    "        # Save the differences to an HTML report\n",
    "        comparison_results_df.to_html(f\"{file_path}/comparison_report.html\")\n",
    "\n",
    "        # Modify the HTML report by adding a title tag if it exists or creating a new one\n",
    "        if os.path.exists(f\"{file_path}/comparison_report.html\"):\n",
    "            with open(f\"{file_path}/comparison_report.html\", \"r\") as f:\n",
    "                # Parse the HTML file using BeautifulSoup\n",
    "                soup = BeautifulSoup(f, \"html.parser\")\n",
    "\n",
    "                # Find the head tag in the parsed HTML\n",
    "                head_tag = soup.find(\"head\")\n",
    "\n",
    "                # If head tag exists, add a title tag with the text \"Comparison Report\"\n",
    "                if head_tag:\n",
    "                    title_tag = soup.new_tag(\"title\")\n",
    "                    title_tag.string = \"Comparison Report\"\n",
    "                    head_tag.append(title_tag)\n",
    "                else:\n",
    "                    # If head tag doesn't exist, create a new head tag and add the title tag\n",
    "                    head_tag = soup.new_tag(\"head\")\n",
    "                    soup.insert(0, head_tag)\n",
    "                    title_tag = soup.new_tag(\"title\")\n",
    "                    title_tag.string = \"Comparison Report\"\n",
    "                    head_tag.append(title_tag)\n",
    "\n",
    "                    # Write the modified HTML back to the file\n",
    "                with open(f\"{file_path}/comparison_report.html\", \"w\") as f:\n",
    "                    f.write(str(soup))\n",
    "                print(f\"Report has been generated at {file_path}\")\n",
    "\n",
    "    return open_html_file(f\"{file_path}/comparison_report.html\")\n",
    "\n",
    "#Function to generate CSV report\n",
    "def generate_csv_report(comparison_results_df, file_path):\n",
    "    \"\"\"\n",
    "    Write a pandas DataFrame to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): The DataFrame to be written to CSV.\n",
    "        file_path (str): The file path along with the filename where the CSV file should be saved.\n",
    "    \"\"\"\n",
    "    comparison_results_df.to_csv(file_path, index=False)\n",
    "    print(f\"Report has been generated at {file_path}\")\n",
    "    \n",
    "#Function to generate EXCEL report\n",
    "def generate_excel_report(comparison_results_df,filename ):\n",
    "    # Create a Pandas Excel writer using the filename\n",
    "    writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n",
    "\n",
    "    # Write the DataFrame to the Excel file\n",
    "    comparison_results_df.to_excel(writer, index=True)\n",
    "\n",
    "    # Save the Excel file\n",
    "    writer.save()\n",
    "    print(f\"Report has been generated at {filename}\")\n",
    "    \n",
    "#Function to open html report in browser\n",
    "def open_html_file(file_name):\n",
    "    webbrowser.open(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aed1435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to compare the files having record count mismatch\n",
    "def compare_files_for_count_diff(file_path, df1, df2):\n",
    "    try:\n",
    "    \n",
    "        # Flag to check if there is a record count difference\n",
    "        count_check = True\n",
    "\n",
    "        # Check if there is a record count difference between the two tables\n",
    "        if len(df1) != len(df2):\n",
    "            print(\"There is a record count difference between the two files.\")\n",
    "\n",
    "            # Get the rows that are present in df_oracle but not in df_athena\n",
    "            df_difference = pd.concat([df2, df1]).drop_duplicates(keep=False)\n",
    "            return df_difference\n",
    "            \n",
    "        else:\n",
    "            print(\"Record counts are matching between the two files.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "#Function to compare the data between the 2 files.\n",
    "def compare_files(file_path, df1, df2):\n",
    "    try:\n",
    "        # Flag to check if there is a record count difference\n",
    "        count_check = True\n",
    "        \n",
    "        df = compare_files_for_count_diff(file_path, df1, df2)\n",
    "        # Check if there is a record count difference between the two tables\n",
    "        if len(df)!=0:\n",
    "            print(\"There is a record count difference between the two tables.\")\n",
    "            count_check = False\n",
    "            return df\n",
    "\n",
    "        # If the record count is the same, compare the data in the DataFrames\n",
    "        if count_check:\n",
    "\n",
    "            # Compare the data in df_athena and df_oracle\n",
    "            df_diff = df1.compare(df2, align_axis=1)\n",
    "            return df_diff\n",
    "    except:\n",
    "        print(f\"File is not available at {file_path}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70c48fa",
   "metadata": {},
   "source": [
    "oracle athena comparison<br>\n",
    "oracle and redshift<br>\n",
    "athena and redshift<br>\n",
    "s3 and oracle<br>\n",
    "oracle and RDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0716dd78",
   "metadata": {},
   "source": [
    "table name check<br>\n",
    "field name check<br>\n",
    "datatype check<br>\n",
    "data check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efc507b",
   "metadata": {},
   "source": [
    "# Athena Vs Oracle (Field Name and Datatype check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c34b9cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cx_Oracle\n",
    "import boto3\n",
    "#cx_Oracle.init_oracle_client(lib_dir=r\"C:\\Users\\manis\\Downloads\\instantclient-basic-windows.x64-21.10.0.0.0dbru\\instantclient_21_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac740353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oracle_columns(user, password, host, port, service_name, table_name):\n",
    "    \"\"\"\n",
    "    Connects to Oracle database and retrieves the columns of a specific table.\n",
    "\n",
    "    Args:\n",
    "        user (str): Oracle database username.\n",
    "        password (str): Oracle database password.\n",
    "        host (str): Oracle database host.\n",
    "        port (int): Oracle database port.\n",
    "        service_name (str): Oracle database service name.\n",
    "        table_name (str): Name of the table to retrieve columns from.\n",
    "\n",
    "    Returns:\n",
    "        list: List of Oracle column descriptions.\n",
    "\n",
    "    \"\"\"\n",
    "    oracle_connection = cx_Oracle.connect(f\"{user}/{password}@{host}:{port}/{service_name}\")\n",
    "    oracle_cursor = oracle_connection.cursor()\n",
    "    oracle_cursor.execute(f\"SELECT * FROM {table_name} WHERE 1=0\")\n",
    "    oracle_columns = oracle_cursor.description\n",
    "    oracle_cursor.close()\n",
    "    oracle_connection.close()\n",
    "    return oracle_columns\n",
    "\n",
    "def get_athena_datatype(cx_oracle_datatype):\n",
    "    \"\"\"\n",
    "    Returns the corresponding Athena datatype for the given cx_Oracle datatype.\n",
    "    Args:\n",
    "        cx_oracle_datatype: The cx_Oracle datatype.\n",
    "    Returns:\n",
    "        The corresponding Athena datatype.\n",
    "    \"\"\"\n",
    "    if cx_oracle_datatype[1].name in [\"DB_TYPE_VARCHAR\",\"DB_TYPE_CHAR\", \"DB_TYPE_NCHAR\", \"DB_TYPE_VARCHAR2\", \"DB_TYPE_NVARCHAR2\", \"DB_TYPE_LONG\"]:\n",
    "        return \"STRING\"\n",
    "    elif cx_oracle_datatype[1].name in [\"DB_TYPE_NUMBER\"] and cx_oracle_datatype[5]==0:\n",
    "        return \"INT\"\n",
    "    elif cx_oracle_datatype[1].name in [\"DB_TYPE_NUMBER\", \"DB_TYPE_FLOAT\", \"DB_TYPE_DOUBLE\", \"DB_TYPE_BINARY_FLOAT\", \"DB_TYPE_BINARY_DOUBLE\"]:\n",
    "        return \"DOUBLE\"\n",
    "    elif cx_oracle_datatype[1].name == \"DB_TYPE_DATE\":\n",
    "        return \"DATE\"\n",
    "    elif cx_oracle_datatype[1].name == \"DB_TYPE_TIMESTAMP\":\n",
    "        return \"TIMESTAMP\"\n",
    "    elif cx_oracle_datatype[1].name in [\"DB_TYPE_BLOB\", \"DB_TYPE_CLOB\", \"DB_TYPE_NCLOB\"]:\n",
    "        return \"STRING\"  # Consider using \"BINARY\" for BLOB if necessary\n",
    "    elif cx_oracle_datatype[1].name in [\"DB_TYPE_RAW\", \"DB_TYPE_LONG_RAW\"]:\n",
    "        return \"BINARY\"\n",
    "    elif cx_oracle_datatype[1].name in [\"DB_TYPE_ROWID\", \"DB_TYPE_UROWID\"]:\n",
    "        return \"STRING\"\n",
    "    elif cx_oracle_datatype[1].name == \"DB_TYPE_BOOLEAN\":\n",
    "        return \"BOOLEAN\"\n",
    "    elif cx_oracle_datatype[1].name == \"DB_TYPE_INTERVAL\":\n",
    "        return \"STRING\"\n",
    "    elif cx_oracle_datatype[1].name in [\"DB_TYPE_XML\", \"DB_TYPE_GEOMETRY\", \"DB_TYPE_TOPO_GEOMETRY\", \"DB_TYPE_GEORASTER\"]:\n",
    "        return \"STRING\"\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported cx_Oracle datatype: {}\".format(cx_oracle_datatype.name))\n",
    "\n",
    "\n",
    "def oracle_equivalent_athena_datatypes(username, password, host, port, service_name, table_name):\n",
    "    cx_oracle_datatypes = get_oracle_columns(username, password, host, port, service_name, table_name)\n",
    "    \n",
    "    l = []\n",
    "    for cx_oracle_datatype in cx_oracle_datatypes:\n",
    "        athena_datatypes = {}\n",
    "        athena_datatype = get_athena_datatype(cx_oracle_datatype)\n",
    "        athena_datatypes['Name']=cx_oracle_datatype[0].lower()\n",
    "        athena_datatypes['Type']=athena_datatype.lower()\n",
    "        l.append(athena_datatypes)\n",
    "    return l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "13a2334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_athena_columns(region, database, athena_table):\n",
    "    \"\"\"\n",
    "    Connects to Athena and retrieves the columns of a specific table.\n",
    "\n",
    "    Args:\n",
    "        region (str): AWS region name.\n",
    "        database (str): Athena database name.\n",
    "        athena_table (str): Name of the Athena table to retrieve columns from.\n",
    "\n",
    "    Returns:\n",
    "        list: List of Athena column descriptions.\n",
    "\n",
    "    \"\"\"\n",
    "    # Connect to Athena\n",
    "    athena_client = boto3.client('athena', region_name=region)\n",
    "    \n",
    "    # Get the Athena table schema\n",
    "    response = athena_client.get_table_metadata(\n",
    "        CatalogName='AwsDataCatalog',\n",
    "        DatabaseName=database,\n",
    "        TableName=athena_table\n",
    "    )\n",
    "    \n",
    "    athena_columns = response['TableMetadata']['Columns']\n",
    "    return athena_columns\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ae584370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_list_of_dicts_to_text(data, file_path):\n",
    "    \"\"\"\n",
    "    Write a list of dictionaries to a text file.\n",
    "\n",
    "    Args:\n",
    "        data (list[dict]): The list of dictionaries to be written.\n",
    "        file_path (str): The file path along with the filename where the text file should be saved.\n",
    "    \"\"\"\n",
    "    if len(data) == 0:\n",
    "        with open(file_path, 'w') as file:\n",
    "            file.write(\"No difference found in Datatypes.\")\n",
    "    else:\n",
    "        with open(file_path, 'w') as file:\n",
    "            for dictionary in data:\n",
    "                for key, value in dictionary.items():\n",
    "                    file.write(f\"{key}: {value}\\n\")\n",
    "                file.write(\"\\n\")\n",
    "                \n",
    "def compare_oracle_vs_athena_data_types(ora_user, ora_pwd, host, port, service_name, ora_tab_name,region, athena_db, athena_table):\n",
    "    \"\"\"\n",
    "    Compares the data types of columns between Athena and Oracle tables.\n",
    "\n",
    "    Args:\n",
    "        athena_columns (list): List of Athena column descriptions.\n",
    "        oracle_columns (list): List of Oracle column descriptions.\n",
    "\n",
    "    Returns:\n",
    "        list: List of differences in column data types.\n",
    "\n",
    "    \"\"\"\n",
    "    athena_columns = get_athena_columns(region, athena_db, athena_table)\n",
    "    oracle_columns = oracle_equivalent_athena_datatypes(ora_user, ora_pwd, host, port, service_name, ora_tab_name)\n",
    "    differences = []\n",
    "    for athena_col, oracle_col in zip(athena_columns, oracle_columns):\n",
    "        athena_col_name = athena_col['Name']\n",
    "        athena_data_type = athena_col['Type']\n",
    "\n",
    "        oracle_col_name = oracle_col['Name']\n",
    "        oracle_data_type = oracle_col['Type']\n",
    "\n",
    "        if athena_data_type != oracle_data_type:\n",
    "            difference = {\n",
    "                    'column': athena_col_name,\n",
    "                    'athena_data_type': athena_data_type,\n",
    "                    'oracle_data_type': oracle_data_type\n",
    "                }\n",
    "            differences.append(difference)\n",
    "    if differences:\n",
    "        print('Differences found:')\n",
    "        for diff in differences:\n",
    "            print(diff)\n",
    "    else:\n",
    "        print('No differences found.') \n",
    "    return differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c7e404",
   "metadata": {},
   "source": [
    "# Data comparison between athena and oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ed59709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cx_Oracle\n",
    "import pandas as pd\n",
    "\n",
    "def read_oracle_table(username, password, host, port, service_name, table_name):\n",
    "    \"\"\"\n",
    "    Reads data from an Oracle table and returns a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        username (str): The username to connect to the Oracle database.\n",
    "        password (str): The password to connect to the Oracle database.\n",
    "        host (str): The hostname or IP address of the Oracle database server.\n",
    "        port (int): The port number to connect to the Oracle database.\n",
    "        service_name (str): The service name of the Oracle database.\n",
    "        table_name (str): The name of the table to fetch data from.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the data from the Oracle table.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Establish a connection to the Oracle database\n",
    "    connection = cx_Oracle.connect(f'{username}/{password}@{host}:{port}/{service_name}')\n",
    "\n",
    "    # Create a cursor object\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Execute a query to fetch data from the Oracle table\n",
    "    query = f'SELECT * FROM {table_name}'\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # Fetch all the rows from the cursor\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    # Get the column names from the cursor description\n",
    "    column_names = [desc[0] for desc in cursor.description]\n",
    "\n",
    "    # Create a pandas DataFrame from the fetched data and column names\n",
    "    df = pd.DataFrame(rows, columns=column_names)\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bdc88db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_value(value, data_type):\n",
    "    \"\"\"\n",
    "    Casts the value to the specified data type.\n",
    "\n",
    "    Args:\n",
    "        value: The value to be casted.\n",
    "        data_type: The target data type.\n",
    "\n",
    "    Returns:\n",
    "        The casted value.\n",
    "    \"\"\"\n",
    "    if value is None:\n",
    "        return None\n",
    "    \n",
    "    if data_type == 'integer':\n",
    "        return int(value)\n",
    "    elif data_type == 'double':\n",
    "        return float(value)\n",
    "    elif data_type == 'boolean':\n",
    "        return bool(value)\n",
    "    elif data_type == 'date':\n",
    "        return value\n",
    "    elif data_type == 'timestamp':\n",
    "        return value\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "def create_dataframe_from_athena_table(region, database, table, output_location):\n",
    "    \"\"\"\n",
    "    Creates a pandas DataFrame by fetching data from an Athena table.\n",
    "\n",
    "    Args:\n",
    "        region (str): The AWS region name.\n",
    "        database (str): The name of the Athena database.\n",
    "        table (str): The name of the Athena table to fetch data from.\n",
    "        output_location (str): The S3 bucket location to store the query results.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the data from the Athena table.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create an Athena client\n",
    "    athena_client = boto3.client('athena', region_name=region)\n",
    "    \n",
    "    # Execute the query to fetch data from the Athena table\n",
    "    query = f'SELECT * FROM {table}'\n",
    "    response = athena_client.start_query_execution(\n",
    "        QueryString=query,\n",
    "        QueryExecutionContext={\n",
    "            'Database': database\n",
    "        },\n",
    "        ResultConfiguration={\n",
    "            'OutputLocation': output_location\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Get the query execution ID\n",
    "    query_execution_id = response['QueryExecutionId']\n",
    "    \n",
    "    # Wait for the query execution to complete\n",
    "    while True:\n",
    "        query_status = athena_client.get_query_execution(QueryExecutionId=query_execution_id)\n",
    "        status = query_status['QueryExecution']['Status']['State']\n",
    "        if status in ['SUCCEEDED', 'FAILED', 'CANCELLED']:\n",
    "            break\n",
    "        time.sleep(5)  # Wait for 5 seconds before checking the query status again\n",
    "    \n",
    "    # Check if the query execution was successful\n",
    "    if status != 'SUCCEEDED':\n",
    "        raise ValueError(\"Athena query execution failed or was cancelled.\")\n",
    "    \n",
    "    # Get the query results\n",
    "    results = athena_client.get_query_results(QueryExecutionId=query_execution_id)\n",
    "    \n",
    "    # Extract the column names and data types\n",
    "    column_metadata = results['ResultSet']['ResultSetMetadata']['ColumnInfo']\n",
    "    column_names = [field['Name'].upper() for field in column_metadata]\n",
    "    data_types = [field['Type'] for field in column_metadata]\n",
    "    \n",
    "    # Extract the rows\n",
    "    rows = []\n",
    "    for row in results['ResultSet']['Rows'][1:]:\n",
    "        values = []\n",
    "        for i, data in enumerate(row['Data']):\n",
    "            column_type = data_types[i]\n",
    "            \n",
    "            value = data.get('VarCharValue')\n",
    "            \n",
    "            casted_value = cast_value(value, column_type)\n",
    "            values.append(casted_value)\n",
    "        rows.append(values)\n",
    "    \n",
    "    # Create the pandas DataFrame\n",
    "    df = pd.DataFrame(rows, columns=column_names)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d810e1",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b84f521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_comparison_report():\n",
    "    choice = int(input(\"What kind of comparison you want. Please choose from below options \\n 1. File to File comparison \\n 2. Oracle vs Athena datatype comparison. \\n 3. Oracle vs Athena Data comparison\\n\"))\n",
    "    file_path = input(\"Please enter the location of files: \")\n",
    "    if choice==1:\n",
    "        \n",
    "        file1 = input(\"Please enter first file name: \")\n",
    "        file2 = input(\"Please enter second file name: \")\n",
    "        df1 = pd.read_csv(f\"{file_path}/{file1}\", encoding='latin-1')\n",
    "        df2 = pd.read_csv(f\"{file_path}/{file2}\", encoding='latin-1')\n",
    "        while True:\n",
    "            report_type = input(\"Please enter the format in which you want the report CSV/EXCEL/HTML: \")\n",
    "            if report_type.upper() in [\"CSV\",\"EXCEL\",\"HTML\"]:\n",
    "                break\n",
    "        df = compare_files(file_path, df1, df2)\n",
    "        if report_type.upper() == \"HTML\":\n",
    "            generate_html_report(df,file_path)\n",
    "        elif report_type.upper() == \"CSV\":\n",
    "            generate_csv_report(df, f\"{file_path}/comparison_report.csv\")\n",
    "        elif report_type.upper() == \"EXCEL\":\n",
    "            generate_excel_report(df,f\"{file_path}/comparison_report.xlsx\" )\n",
    "        else:\n",
    "            print(\"Please enter valid file format.\")#C:/Users/manis/Downloads/Comparison\n",
    "    elif choice==2:\n",
    "        ora_user = input(\"USERNAME: \")\n",
    "        ora_pwd = input(\"PASSWORD: \")\n",
    "        host = input(\"HOST: \")\n",
    "        port = int(input(\"PORT: \"))\n",
    "        service_name = input(\"SID/Service Name: \")\n",
    "        ora_tab_name = input(\"Table Name: \")\n",
    "        region = input(\"AWS Region: \")\n",
    "        athena_db = input(\"Athena Database: \")\n",
    "        athena_table = input(\"Athena table name: \")\n",
    "        differences = compare_oracle_vs_athena_data_types(ora_user, ora_pwd, host, port, service_name, ora_tab_name,region, athena_db, athena_table)\n",
    "        write_list_of_dicts_to_text(differences,f\"{file_path}/Datatype_comparison_report.txt\")\n",
    "        differences\n",
    "    elif choice ==3:\n",
    "        ora_user = \"hr\" #input(\"USERNAME: \")\n",
    "        ora_pwd = \"oracle\" #input(\"PASSWORD: \")\n",
    "        host = \"192.168.56.102\" #input(\"HOST: \")\n",
    "        port = 1521 #int(input(\"PORT: \"))\n",
    "        service_name = \"freepdb1\" #input(\"SID/Service Name: \")\n",
    "        ora_tab_name = \"job_history\" #input(\"Table Name: \")\n",
    "        region = \"us-east-1\" #input(\"AWS Region: \")\n",
    "        athena_db = \"test_fw\" #input(\"Athena Database: \")\n",
    "        athena_table = \"job_history\" #input(\"Athena table name: \")\n",
    "        output_location = \"s3://manish600712/Unsaved/\" #input(\"S3 output location: \")\n",
    "        df_athena = create_dataframe_from_athena_table(region, athena_db, athena_table, output_location)\n",
    "        df_oracle = read_oracle_table(ora_user, ora_pwd, host, port, service_name, ora_tab_name)\n",
    "        while True:\n",
    "            report_type = input(\"Please enter the format in which you want the report CSV/EXCEL/HTML: \")\n",
    "            if report_type.upper() in [\"CSV\",\"EXCEL\",\"HTML\"]:\n",
    "                break\n",
    "        df = compare_files(file_path, df_athena, df_oracle)\n",
    "        if report_type.upper() == \"HTML\":\n",
    "            generate_html_report(df,file_path)\n",
    "        elif report_type.upper() == \"CSV\":\n",
    "            generate_csv_report(df, f\"{file_path}/comparison_report.csv\")\n",
    "        elif report_type.upper() == \"EXCEL\":\n",
    "            generate_excel_report(df,f\"{file_path}/comparison_report.xlsx\" )\n",
    "        else:\n",
    "            print(\"Please enter valid file format.\")#C:/Users/manis/Downloads/Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b288d107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What kind of comparison you want. Please choose from below options \n",
      " 1. File to File comparison \n",
      " 2. Oracle vs Athena datatype comparison. \n",
      " 3. Oracle vs Athena Data comparison\n",
      "2\n",
      "Please enter the location of files: C:/Users/manis/Downloads/Comparison\n",
      "USERNAME: hr\n",
      "PASSWORD: oracle\n",
      "HOST: 192.168.56.102\n",
      "PORT: 1521\n",
      "SID/Service Name: freepdb1\n",
      "Table Name: job_hist\n",
      "AWS Region: us-east-1\n",
      "Athena Database: test_fw\n",
      "Athena table name: job_history\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manis\\AppData\\Local\\Temp\\ipykernel_14480\\1342893639.py:31: ResourceWarning: unclosed <ssl.SSLSocket fd=2896, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('192.168.1.7', 48864), raddr=('18.207.23.87', 443)>\n",
      "  athena_columns = get_athena_columns(region, athena_db, athena_table)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences found:\n",
      "{'column': 'department_id', 'athena_data_type': 'int', 'oracle_data_type': 'string'}\n"
     ]
    }
   ],
   "source": [
    "generate_comparison_report()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec42a87",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a0c5f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_spark_to_pandas(spark_df):\n",
    "    \"\"\"\n",
    "    Converts a Spark DataFrame to a Pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        spark_df (pyspark.sql.DataFrame): The Spark DataFrame to be converted.\n",
    "        \n",
    "    Returns:\n",
    "        pandas_df (pandas.DataFrame): The resulting Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    pandas_df = spark_df.toPandas()\n",
    "    return pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8454df7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "def create_pandas_dataframe_from_rds_table(host, port, database, username, password, table_name):\n",
    "    \"\"\"\n",
    "    Create a Pandas DataFrame from a table in a remote RDS database.\n",
    "\n",
    "    Parameters:\n",
    "        host (str): The hostname or IP address of the RDS database.\n",
    "        port (int): The port number for the RDS database.\n",
    "        database (str): The name of the database in the RDS instance.\n",
    "        username (str): The username for the RDS database.\n",
    "        password (str): The password for the RDS database.\n",
    "        table_name (str): The name of the table in the RDS database.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the data from the specified table.\n",
    "\n",
    "    Raises:\n",
    "        psycopg2.OperationalError: If there is an error connecting to the RDS database.\n",
    "\n",
    "    Example:\n",
    "        df = create_pandas_dataframe_from_rds_table(\n",
    "            host='example.com',\n",
    "            port=5432,\n",
    "            database='mydb',\n",
    "            username='user',\n",
    "            password='password',\n",
    "            table_name='mytable'\n",
    "        )\n",
    "    \"\"\"\n",
    "    # Establish a connection to the RDS database\n",
    "    conn = psycopg2.connect(\n",
    "        host=host,\n",
    "        port=port,\n",
    "        database=database,\n",
    "        user=username,\n",
    "        password=password\n",
    "    )\n",
    "\n",
    "    # Create a cursor object to interact with the database\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Execute a SQL query to fetch all data from the table\n",
    "    query = f\"SELECT * FROM {table_name}\"\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # Fetch all rows from the result set\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    # Get the column names from the cursor description\n",
    "    column_names = [desc[0] for desc in cursor.description]\n",
    "\n",
    "    # Create a Pandas DataFrame from the fetched data and column names\n",
    "    df = pd.DataFrame(rows, columns=column_names)\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "037ea406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "def create_pandas_dataframe_from_redshift_table(host, port, database, username, password, table_name):\n",
    "    \"\"\"\n",
    "    Create a Pandas DataFrame from a Redshift table.\n",
    "\n",
    "    Parameters:\n",
    "        host (str): The hostname or IP address of the Redshift cluster.\n",
    "        port (int): The port number used to connect to the Redshift cluster.\n",
    "        database (str): The name of the Redshift database.\n",
    "        username (str): The username used to authenticate the connection.\n",
    "        password (str): The password used to authenticate the connection.\n",
    "        table_name (str): The name of the table from which to fetch the data.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the fetched data from the table.\n",
    "\n",
    "    Raises:\n",
    "        psycopg2.OperationalError: If there is an error in establishing the connection to the Redshift cluster.\n",
    "\n",
    "    Example:\n",
    "        host = 'example-redshift-cluster.com'\n",
    "        port = 5439\n",
    "        database = 'my_database'\n",
    "        username = 'my_username'\n",
    "        password = 'my_password'\n",
    "        table_name = 'my_table'\n",
    "        df = create_pandas_dataframe_from_redshift_table(host, port, database, username, password, table_name)\n",
    "    \"\"\"\n",
    "    # Establish a connection to the Redshift cluster\n",
    "    conn = psycopg2.connect(\n",
    "        host=host,\n",
    "        port=port,\n",
    "        database=database,\n",
    "        user=username,\n",
    "        password=password\n",
    "    )\n",
    "\n",
    "    # Create a cursor object to interact with the database\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Execute a SQL query to fetch all data from the table\n",
    "    query = f\"SELECT * FROM {table_name}\"\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # Fetch all rows from the result set\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    # Get the column names from the cursor description\n",
    "    column_names = [desc[0] for desc in cursor.description]\n",
    "\n",
    "    # Create a Pandas DataFrame from the fetched data and column names\n",
    "    df = pd.DataFrame(rows, columns=column_names)\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e6e2780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "def create_pandas_dataframe_from_rds_table(host, port, database, username, password, table_name):\n",
    "    \"\"\"\n",
    "    Creates a Pandas DataFrame from an RDS table.\n",
    "\n",
    "    Args:\n",
    "        host (str): The hostname or IP address of the RDS instance.\n",
    "        port (int): The port number to connect to the RDS instance.\n",
    "        database (str): The name of the RDS database.\n",
    "        username (str): The username for authentication.\n",
    "        password (str): The password for authentication.\n",
    "        table_name (str): The name of the table in the RDS database.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the data from the RDS table.\n",
    "    \"\"\"\n",
    "\n",
    "    # Establish a connection to the RDS database\n",
    "    conn = psycopg2.connect(\n",
    "        host=host,\n",
    "        port=port,\n",
    "        database=database,\n",
    "        user=username,\n",
    "        password=password\n",
    "    )\n",
    "\n",
    "    # Create a cursor object to interact with the database\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Execute a SQL query to fetch all data from the table\n",
    "    query = f\"SELECT * FROM {table_name}\"\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # Fetch all rows from the result set\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    # Get the column names from the cursor description\n",
    "    column_names = [desc[0] for desc in cursor.description]\n",
    "\n",
    "    # Create a Pandas DataFrame from the fetched data and column names\n",
    "    df = pd.DataFrame(rows, columns=column_names)\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30d33d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "def create_pandas_dataframe_from_s3_parquet_and_pyspark_table(parquet_file_path, spark_table_name):\n",
    "    \"\"\"\n",
    "    Creates a Pandas DataFrame from an S3 Parquet file and a PySpark table.\n",
    "\n",
    "    Args:\n",
    "        parquet_file_path (str): The S3 path of the Parquet file.\n",
    "        spark_table_name (str): The name of the PySpark table.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The resulting Pandas DataFrame.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a SparkSession\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "    # Read the Parquet file into a PySpark DataFrame\n",
    "    spark_df = spark.read.parquet(parquet_file_path)\n",
    "\n",
    "    # Register the PySpark DataFrame as a temporary table\n",
    "    spark_df.createOrReplaceTempView(spark_table_name)\n",
    "\n",
    "    # Convert the PySpark table to a Pandas DataFrame\n",
    "    pandas_df = spark.sql(f\"SELECT * FROM {spark_table_name}\").toPandas()\n",
    "\n",
    "    return pandas_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a1d3661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import cx_Oracle\n",
    "\n",
    "def compare_datatypes_redshift_oracle(redshift_conn_params, oracle_conn_params, table_name):\n",
    "    \"\"\"\n",
    "    Compares the data types between Redshift and Oracle databases for a given table.\n",
    "\n",
    "    Args:\n",
    "        redshift_conn_params (dict): A dictionary containing the connection parameters for Redshift.\n",
    "            Example: {'host': 'your-redshift-hostname', 'port': 5439, 'database': 'your-database-name',\n",
    "                      'username': 'your-username', 'password': 'your-password'}\n",
    "\n",
    "        oracle_conn_params (dict): A dictionary containing the connection parameters for Oracle.\n",
    "            Example: {'host': 'your-oracle-hostname', 'port': 1521, 'database': 'your-database-name',\n",
    "                      'username': 'your-username', 'password': 'your-password'}\n",
    "\n",
    "        table_name (str): The name of the table to compare.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the mapping of column names and their corresponding data types.\n",
    "            Example: {'column1': ('redshift_type', 'oracle_type'), 'column2': ('redshift_type', 'oracle_type'), ...}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Establish a connection to Redshift\n",
    "    redshift_conn = psycopg2.connect(\n",
    "        host=redshift_conn_params['host'],\n",
    "        port=redshift_conn_params['port'],\n",
    "        database=redshift_conn_params['database'],\n",
    "        user=redshift_conn_params['username'],\n",
    "        password=redshift_conn_params['password']\n",
    "    )\n",
    "\n",
    "    # Create a cursor for Redshift\n",
    "    redshift_cursor = redshift_conn.cursor()\n",
    "\n",
    "    # Get the column names and data types from Redshift\n",
    "    redshift_cursor.execute(f\"SELECT column_name, data_type FROM information_schema.columns WHERE table_name='{table_name}'\")\n",
    "    redshift_columns = redshift_cursor.fetchall()\n",
    "\n",
    "    # Establish a connection to Oracle\n",
    "    oracle_conn = cx_Oracle.connect(\n",
    "        f\"{oracle_conn_params['username']}/{oracle_conn_params['password']}@{oracle_conn_params['host']}:\"\n",
    "        f\"{oracle_conn_params['port']}/{oracle_conn_params['database']}\"\n",
    "    )\n",
    "\n",
    "    # Create a cursor for Oracle\n",
    "    oracle_cursor = oracle_conn.cursor()\n",
    "\n",
    "    # Get the column names and data types from Oracle\n",
    "    oracle_cursor.execute(f\"SELECT column_name, data_type FROM all_tab_columns WHERE table_name='{table_name.upper()}'\")\n",
    "    oracle_columns = oracle_cursor.fetchall()\n",
    "\n",
    "    # Close the cursors and connections\n",
    "    redshift_cursor.close()\n",
    "    redshift_conn.close()\n",
    "    oracle_cursor.close()\n",
    "    oracle_conn.close()\n",
    "\n",
    "    # Create a dictionary to store the mapping of column names and data types\n",
    "    column_datatypes = {}\n",
    "\n",
    "    # Compare the data types between Redshift and Oracle\n",
    "    for redshift_col, oracle_col in zip(redshift_columns, oracle_columns):\n",
    "        column_name = redshift_col[0]\n",
    "        redshift_datatype = redshift_col[1]\n",
    "        oracle_datatype = oracle_col[1]\n",
    "\n",
    "        column_datatypes[column_name] = (redshift_datatype, oracle_datatype)\n",
    "\n",
    "    return column_datatypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f1c9e6",
   "metadata": {},
   "source": [
    "# Difference using pysaprk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357e3a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "def compare_dataframes(df1, df2):\n",
    "    # Compare the schemas of the two DataFrames\n",
    "    if df1.schema != df2.schema:\n",
    "        print(\"The schemas of the two DataFrames are different.\")\n",
    "        return\n",
    "    \n",
    "    # Compare the data in the two DataFrames\n",
    "    common_records = df1.intersect(df2)\n",
    "    diff_in_df1 = df1.subtract(common_records)\n",
    "    diff_in_df2 = df2.subtract(common_records)\n",
    "    \n",
    "    if diff_in_df1.count() == 0 and diff_in_df2.count() == 0:\n",
    "        print(\"The data in the two DataFrames is identical.\")\n",
    "        return\n",
    "    \n",
    "    # Write the differences to separate files\n",
    "    common_records_output_path = \"common_records.csv\"\n",
    "    diff_in_df1_output_path = \"diff_in_df1.csv\"\n",
    "    diff_in_df2_output_path = \"diff_in_df2.csv\"\n",
    "    \n",
    "    common_records.write.format(\"csv\").option(\"header\", \"true\").mode(\"overwrite\").save(common_records_output_path)\n",
    "    diff_in_df1.write.format(\"csv\").option(\"header\", \"true\").mode(\"overwrite\").save(diff_in_df1_output_path)\n",
    "    diff_in_df2.write.format(\"csv\").option(\"header\", \"true\").mode(\"overwrite\").save(diff_in_df2_output_path)\n",
    "    \n",
    "    print(f\"Common records between the two DataFrames are saved to {common_records_output_path} in CSV format.\")\n",
    "    print(f\"Differences found in df1 are saved to {diff_in_df1_output_path} in CSV format.\")\n",
    "    print(f\"Differences found in df2 are saved to {diff_in_df2_output_path} in CSV format.\")\n",
    "\n",
    "# Read the two files into Spark DataFrames\n",
    "df1 = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"oracle.csv\")\n",
    "df2 = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"athena.csv\")\n",
    "\n",
    "# Compare the DataFrames\n",
    "compare_dataframes(df1, df2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
